# ConverseGPT

## About The Project

Easily chat with your local LLM. ConverseGPT is seamlessly integrated into your workflow; just open the app to start a conversation with your AI.

A demo is available on the [website](https://converse-gpt.vercel.app).
## How To Use

ConverseGPT is currently compatible with macOS, Windows, Linux and utilizes Ollama for its operation. Follow the steps below to get started:

1. **Download Ollama:** Visit [https://ollama.com/](https://ollama.com/) to download the Ollama software.
2. **Install a Local LLM:** Use the command `ollama pull model_name` in your terminal to install the local LLM you wish to use.
3. **Verify Ollama is Running:** Ensure that the Ollama application is running correctly. You should see the Ollama logo displayed in your top bar.
4. **Download ConverseGPT** 
5. **Launch ConverseGPT:** After downloading directly launch the app.


## Features
1. Carry on conversations
2. Stop seeing previous outputs

## Testing And Building The Project
- **Test**: npm run start
   
## What's Next

- [ ] Multimodal language support, allowing the interface to process images.
- [ ] Eliminate the dependency on Ollama to streamline the installation process.
- [ ] Feature to save LLM responses permanently, enabling easy retrieval for future reference.
## Links
[Website](https://converse-gpt.vercel.app)

Contributions, feedback, and suggestions are more than welcomed.\
You can also reach out to me on [twitter](https://twitter.com/Mayank_2107) if you have any question.
